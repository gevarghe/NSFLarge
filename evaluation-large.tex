\section{Evaluation}

We plan to evaluate the tasks presented in the preceding section as follows:
\begin{itemize}
\item {\bf S1:} We will evaluate our topology synthesis tools on synthetic benchmarks, and will seek to deploy variants of these tools through collaborations with industry partners.
\item {\bf S2:}  We will evaluate the extension of stepwise refinement to evaluate the Google Maglev load balancer, something beyond the capabilities of network verification tools today.  We will work with Bjorner and Lopes at Microsoft to evaluate the new ideas for scalable verification based on transitive closure on the Microsoft data set we used in previous work~\cite{surgeries}.
\item {\bf S7:} We will instrument Gumaste's existing SDN testbed at IIT Mumbai with performance queries, and measure the overhead and completeness of the approach for several common monitoring tasks.
\item {\bf S8:} We will develop mining software that we will deploy at Google to evaluate whether we emulate all of PI Govindan's earlier manual analysis~\cite{rameshgoogle}, while scaling to larger inputs.
\end{itemize}
Additionally, in the fourth year, we will deploy a end-to-end demonstration using a small cluster of new reconfigurable router designs (using an FPGA) at IIT Mumbai, add new router measurement capabilities using our compiler, design the network topology using our synthesis tool, synthesize configurations using stepwise refinement, and finally monitor the network using performance queries.  While this only exercises a subset of our tasks, the others (e.g., failure analysis) can only be evaluated outside the laboratory.
